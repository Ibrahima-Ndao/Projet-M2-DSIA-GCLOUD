{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: google-cloud-storage in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (3.27.0)\n",
      "Requirement already satisfied: google-auth<3.0dev,>=2.26.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (2.37.0)\n",
      "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (2.24.0)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media>=2.7.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (2.32.3)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-storage) (1.6.0)\n",
      "Requirement already satisfied: packaging>=20.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (23.2)\n",
      "Requirement already satisfied: python-dateutil<3.0dev,>=2.7.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-cloud-bigquery) (2.8.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.66.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (5.28.3)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage) (1.25.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.69.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-api-core[grpc]<3.0.0dev,>=2.11.1->google-cloud-bigquery) (1.69.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from google-auth<3.0dev,>=2.26.1->google-cloud-storage) (4.9)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil<3.0dev,>=2.7.3->google-cloud-bigquery) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.7.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.26.1->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install google-cloud-storage google-cloud-bigquery\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage, bigquery\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Étape 1 : Configuration des ressources GCP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration de base\n",
    "PROJECT_ID = \"isi-group-m2-dsia\"\n",
    "BUCKET_NAME = \"m2dsia-ndao-ibrahima-data\"\n",
    "DATASET_NAME = 'dataset_ndao_ibrahima'\n",
    "TABLE_NAME = 'auchan_sales'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = storage.Client(project=PROJECT_ID)\n",
    "bucket = client.get_bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Bucket: m2dsia-ndao-ibrahima-data>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder_bucket(bucket_name):\n",
    "    # Define folder structure\n",
    "    folders = [\"input/\", \"clean/\", \"error/\", \"done/\"]\n",
    "    for folder in folders:\n",
    "        blob = bucket.blob(folder)\n",
    "        blob.upload_from_string('')  # Create an empty folder\n",
    "        print(f\"Folder {folder} created in bucket {bucket_name}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder input/ created in bucket m2dsia-ndao-ibrahima-data.\n",
      "Folder clean/ created in bucket m2dsia-ndao-ibrahima-data.\n",
      "Folder error/ created in bucket m2dsia-ndao-ibrahima-data.\n",
      "Folder done/ created in bucket m2dsia-ndao-ibrahima-data.\n"
     ]
    }
   ],
   "source": [
    "create_folder_bucket(BUCKET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean/\n",
      "done/\n",
      "error/\n",
      "input/\n",
      "tp/\n",
      "tp/Copie de Copie de auchan_sales_data.csv\n",
      "tp/Copie de auchan_sales_data.csv\n",
      "tp/auchan_sales_data.csv\n"
     ]
    }
   ],
   "source": [
    "blobs = client.list_blobs(BUCKET_NAME)\n",
    "for blob in blobs:\n",
    "    print(blob.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigquery_table(project_id, dataset_name, table_name):\n",
    "    \"\"\"Create a BigQuery dataset and table.\"\"\"\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # Create dataset\n",
    "    dataset_id = f\"{project_id}.{dataset_name}\"\n",
    "    dataset = bigquery.Dataset(dataset_id)\n",
    "    dataset.location = \"africa-south1\"  # Adjust region as needed\n",
    "    dataset = client.create_dataset(dataset, exists_ok=True)\n",
    "    print(f\"Dataset {dataset_id} created or already exists.\")\n",
    "\n",
    "    # Define table schema\n",
    "    schema = [\n",
    "        bigquery.SchemaField(\"transaction_id\", \"INT64\", mode=\"REQUIRED\", description=\"Identifiant unique\"),\n",
    "        bigquery.SchemaField(\"product_name\", \"STRING\", mode=\"REQUIRED\", description=\"Nom du produit\"),\n",
    "        bigquery.SchemaField(\"category\", \"STRING\", mode=\"REQUIRED\", description=\"Catégorie du produit\"),\n",
    "        bigquery.SchemaField(\"price\", \"FLOAT64\", mode=\"REQUIRED\", description=\"Prix unitaire\"),\n",
    "        bigquery.SchemaField(\"quantity\", \"INT64\", mode=\"REQUIRED\", description=\"Quantité achetée\"),\n",
    "        bigquery.SchemaField(\"date\", \"DATE\", mode=\"REQUIRED\", description=\"Date de la transaction\"),\n",
    "        bigquery.SchemaField(\"customer_name\", \"STRING\", mode=\"NULLABLE\", description=\"Nom du client\"),\n",
    "        bigquery.SchemaField(\"customer_email\", \"STRING\", mode=\"NULLABLE\", description=\"E-mail du client\"),\n",
    "    ]\n",
    "\n",
    "    table_id = f\"{dataset_id}.{table_name}\"\n",
    "    table = bigquery.Table(table_id, schema=schema)\n",
    "\n",
    "    # Set partitioning and clustering\n",
    "    table.time_partitioning = bigquery.TimePartitioning(\n",
    "        type_=bigquery.TimePartitioningType.DAY,\n",
    "        field=\"date\"  # Specify the partitioning field\n",
    "    )\n",
    "    table.clustering_fields = [\"category\", \"product_name\"]\n",
    "\n",
    "    # Create the table\n",
    "    table = client.create_table(table, exists_ok=True)\n",
    "    print(f\"Table {table_id} created or already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset isi-group-m2-dsia.dataset_ndao_ibrahima created or already exists.\n",
      "Table isi-group-m2-dsia.dataset_ndao_ibrahima.auchan_sales created or already exists.\n"
     ]
    }
   ],
   "source": [
    "create_bigquery_table(PROJECT_ID, DATASET_NAME, TABLE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (2.2.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.0 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_from_gcs(bucket_name, file_path):\n",
    "    \"\"\"Download a file from Google Cloud Storage.\"\"\"\n",
    "    # Télécharger le fichier comme texte\n",
    "    data = blob.download_as_text()\n",
    "    print(f\"File {file_path} downloaded successfully from bucket {bucket_name}.\")\n",
    "    \n",
    "    # Charger le contenu dans un DataFrame\n",
    "    dataframe = pd.read_csv(io.StringIO(data))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"tp/auchan_sales_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File tp/auchan_sales_data.csv downloaded successfully from bucket m2dsia-ndao-ibrahima-data.\n"
     ]
    }
   ],
   "source": [
    "dataframe = download_file_from_gcs(BUCKET_NAME, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>category</th>\n",
       "      <th>product</th>\n",
       "      <th>qty</th>\n",
       "      <th>price</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25/01/2025</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Cola 2L</td>\n",
       "      <td>65</td>\n",
       "      <td>1.8</td>\n",
       "      <td>117.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18/01/2025</td>\n",
       "      <td>Hygiene</td>\n",
       "      <td>Soap Bar</td>\n",
       "      <td>159</td>\n",
       "      <td>1.0</td>\n",
       "      <td>159.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02/01/2025</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Mineral Water 6x1.5L</td>\n",
       "      <td>214</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07/01/2025</td>\n",
       "      <td>Hygiene</td>\n",
       "      <td>Soap Bar</td>\n",
       "      <td>175</td>\n",
       "      <td>1.0</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04/01/2025</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>Cola 2L</td>\n",
       "      <td>75</td>\n",
       "      <td>1.8</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date   category               product  qty  price  revenue\n",
       "0  25/01/2025  Beverages               Cola 2L   65    1.8    117.0\n",
       "1  18/01/2025    Hygiene              Soap Bar  159    1.0    159.0\n",
       "2  02/01/2025  Beverages  Mineral Water 6x1.5L  214    3.0    642.0\n",
       "3  07/01/2025    Hygiene              Soap Bar  175    1.0    175.0\n",
       "4  04/01/2025  Beverages               Cola 2L   75    1.8    135.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_bigquery(dataframe, project_id, dataset_name, table_name):\n",
    "    \"\"\"Upload a Pandas DataFrame to a BigQuery table.\"\"\"\n",
    "    if dataframe is None or not isinstance(dataframe, pd.DataFrame):\n",
    "        raise ValueError(\"Le DataFrame fourni est invalide.\")\n",
    "    if dataframe.empty:\n",
    "        raise ValueError(\"Le DataFrame est vide.\")\n",
    "\n",
    "    # Convertir les types si nécessaire\n",
    "    dataframe['date'] = pd.to_datetime(dataframe['date'], errors='coerce')\n",
    "    dataframe['qty'] = pd.to_numeric(dataframe['qty'], errors='coerce')\n",
    "    dataframe['price'] = pd.to_numeric(dataframe['price'], errors='coerce')\n",
    "    dataframe['revenue'] = pd.to_numeric(dataframe['revenue'], errors='coerce')\n",
    "\n",
    "    print(\"Aperçu du DataFrame avant chargement :\")\n",
    "    print(dataframe.info())\n",
    "    print(dataframe.head())\n",
    "\n",
    "    client = bigquery.Client()\n",
    "    table_id = f\"{project_id}.{dataset_name}.{table_name}\"\n",
    "\n",
    "    # Configuration du job\n",
    "    job_config = bigquery.LoadJobConfig(\n",
    "        write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    "        source_format=bigquery.SourceFormat.CSV,\n",
    "        autodetect=True,\n",
    "    )\n",
    "\n",
    "    # Chargement dans BigQuery\n",
    "    try:\n",
    "        job = client.load_table_from_dataframe(dataframe, table_id, job_config=job_config)\n",
    "        job.result()  # Attend la fin du job\n",
    "        print(f\"Les données ont été chargées avec succès dans {table_id}.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données dans BigQuery : {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Windows\\Temp\\ipykernel_6968\\2973799868.py:9: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  dataframe['date'] = pd.to_datetime(dataframe['date'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du DataFrame avant chargement :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 6 columns):\n",
      " #   Column    Non-Null Count  Dtype         \n",
      "---  ------    --------------  -----         \n",
      " 0   date      1000 non-null   datetime64[ns]\n",
      " 1   category  1000 non-null   object        \n",
      " 2   product   1000 non-null   object        \n",
      " 3   qty       1000 non-null   int64         \n",
      " 4   price     1000 non-null   float64       \n",
      " 5   revenue   1000 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(2), int64(1), object(2)\n",
      "memory usage: 47.0+ KB\n",
      "None\n",
      "        date   category               product  qty  price  revenue\n",
      "0 2025-01-25  Beverages               Cola 2L   65    1.8    117.0\n",
      "1 2025-01-18    Hygiene              Soap Bar  159    1.0    159.0\n",
      "2 2025-01-02  Beverages  Mineral Water 6x1.5L  214    3.0    642.0\n",
      "3 2025-01-07    Hygiene              Soap Bar  175    1.0    175.0\n",
      "4 2025-01-04  Beverages               Cola 2L   75    1.8    135.0\n",
      "Erreur lors du chargement des données dans BigQuery : 'NoneType' object has no attribute 'MultiIndex'\n"
     ]
    }
   ],
   "source": [
    "upload_to_bigquery(dataframe, PROJECT_ID, DATASET_NAME, TABLE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
